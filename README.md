# EduPulse: Real-Time Adaptive Learning Platform

> **AI-powered adaptive learning with Confluent Kafka, Avro, and real-time engagement detection**

## Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Repository Structure](#repository-structure)
- [Quick Start](#quick-start)
- [Backend Services](./backend/README.md)
- [Frontend Applications](./frontend/README.md)
- [Cloud & Infrastructure](./infra/README.md)
- [Schema Registry & Avro](#schema-registry--avro)
- [Demo Instructions](#demo-instructions)
- [Troubleshooting](#troubleshooting)

---

## Overview

EduPulse is a real-time adaptive learning platform that detects student disengagement and intervenes during active
learning sessions using AI-driven decision-making powered by Confluent Kafka.

**Key Features:**

- Real-time engagement scoring from student interactions
- AI-powered difficulty adjustment (Vertex AI multi-armed bandit)
- Contextual hint generation (Google Gemini)
- Live instructor coaching tips
- Event-driven architecture with Kafka as system of record
- Strict schema governance with Avro and Confluent Schema Registry

**Technology Stack:**

- **Backend:** Spring Boot 3.5, Java 21
- **Stream Processing:** Apache Flink 1.18+
- **Frontend:** Next.js 15, React 19, TypeScript
- **Messaging:** Confluent Kafka, Schema Registry, Avro
- **AI/ML:** Vertex AI, Google Gemini
- **Data:** PostgreSQL, Redis
- **Deployment:** Docker, Google Cloud (Cloud SQL, Memorystore), Confluent Cloud

---

## Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            Frontend Layer                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Student Learning UI         â”‚  â”‚  Instructor Dashboard           â”‚  â”‚
â”‚  â”‚  (Next.js)                   â”‚  â”‚  (Next.js)                      â”‚  â”‚
â”‚  â”‚  - Question display          â”‚  â”‚  - Engagement heatmap           â”‚  â”‚
â”‚  â”‚  - Answer submission         â”‚  â”‚  - Real-time tips panel         â”‚  â”‚
â”‚  â”‚  - Hint rendering            â”‚  â”‚  - Student drill-down           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                                 â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ SSE (Server-Sent Events)        â”‚
                  â–¼                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Realtime Gateway (Spring Boot MVC)                 â”‚
|          (Kafka Consumer â†’ SSE Fan-out ONLY)                â”‚
â”‚  â€¢ Consumes derived topics                                  â”‚
â”‚  â€¢ Routes by sessionId/studentId/cohortId                   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ RealtimeEventConsumer (Kafka Consumer)            â”‚      â”‚
â”‚  â”‚ @KafkaListener                                    â”‚      â”‚
â”‚  â”‚  - Consumes: engagement.scores, adapt.actions     â”‚      â”‚
â”‚  â”‚  - Deserializes: Avro â†’ Java POJO                 â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚              â”‚                                              â”‚
â”‚              â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ EventBroadcaster (Internal Publisher)             â”‚      â”‚
â”‚  â”‚  - Routes events by studentId/instructorId        â”‚      â”‚
â”‚  â”‚  - Converts Avro â†’ JSON-safe DTO                  â”‚      â”‚
â”‚  â”‚  - Publishes to SseEmitterManager                 â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚              â”‚                                              â”‚
â”‚              â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ SseEmitterManager (Connection Registry)           â”‚      â”‚
â”‚  â”‚  - Map<String, SseEmitter> studentEmitters        â”‚      â”‚
â”‚  â”‚  - Map<String, SseEmitter> instructorEmitters     â”‚      â”‚
â”‚  â”‚  - Handles timeouts, cleanup                      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚              â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  SSE Endpoints                       â”‚
    â”‚  GET /sse/student/{studentId}        â”‚
    â”‚  GET /sse/instructor/{instructorId}  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTP/1.1 chunked transfer
                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Browser (EventSource)               â”‚
    â”‚  - Next.js React Hook                â”‚
    â”‚  - Auto-reconnect on disconnect      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Confluent Kafka Cluster                      â”‚
â”‚  Raw Topics: quiz.answers, session.events                  â”‚
â”‚  Derived Topics: engagement.scores, adapt.actions,         â”‚
â”‚                  instructor.tips, cohort.heatmap,          â”‚
â”‚                  decision.context                          â”‚
â”‚  (Schema Registry enforces Avro schemas - BACKWARD compat) â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                                â”‚
      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  â”‚    Confluent Flink (Managed Stream Processing)   â”‚
      â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
      â”‚  â”‚  â”‚  Engagement Analytics Job                â”‚    â”‚
      â”‚  â”‚  â”‚  â€¢ Windowed metrics (60s tumbling)       â”‚    â”‚
      â”‚  â”‚  â”‚  â€¢ Pattern detection (CEP)               â”‚    â”‚
      â”‚  â”‚  â”‚  â€¢ Enrichment joins                      â”‚    â”‚
      â”‚  â”‚  â”‚  IN: quiz.answers, session.events        â”‚    â”‚
      â”‚  â”‚  â”‚  OUT: engagement.scores, decision.contextâ”‚    â”‚
      â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
      â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
      â”‚  â”‚  â”‚  Instructor Metrics Job                  â”‚    â”‚
      â”‚  â”‚  â”‚  â€¢ Cohort aggregates (5-min sliding)     â”‚    â”‚
      â”‚  â”‚  â”‚  â€¢ Heatmap data generation               â”‚    â”‚
      â”‚  â”‚  â”‚  â€¢ Skill-level struggle detection        â”‚    â”‚
      â”‚  â”‚  â”‚  IN: engagement.scores, quiz.answers     â”‚    â”‚
      â”‚  â”‚  â”‚  OUT: cohort.heatmap, instructor.tips    â”‚    â”‚
      â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â”€> Event Ingest Service (HTTP â†’ Kafka producer)
      â”œâ”€â”€> Bandit Engine (Kafka consumer â†’ Vertex AI â†’ Kafka producer)
      â”œâ”€â”€> Tip Service (Kafka consumer â†’ Gemini â†’ Kafka producer)
      â””â”€â”€> Content Adapter (Kafka consumer â†’ enriches adapt.actions)
```

### Real-Time Pipeline

EduPulse uses a **strict separation of concerns** for real-time data processing:

**Event Flow:**

```
Raw Events (Frontend)
  â†’ Event Ingest Service
  â†’ Kafka Raw Topics
  â†’ Kafka Stream Processing (compute, joins, windowing)
  â†’ Kafka Derived Topics
  â†’ Realtime Gateway (fan-out only)
  â†’ Next.js Frontend (SSE)
```

**Responsibilities:**

1. **Flink (Confluent Managed)**: ALL real-time computation
    - Windowed aggregations (tumbling, sliding, session windows)
    - Stream joins (enrichment, temporal joins)
    - Pattern detection (Complex Event Processing)
    - Stateful transformations
    - Reads Avro from raw topics via Schema Registry
    - Writes Avro to derived topics via Schema Registry

2. **Realtime Gateway (Spring Boot Service)**: Fan-out and routing ONLY
    - Consumes derived topics from Kafka
    - Routes messages by routing keys (sessionId, studentId, cohortId)
    - Pushes to Next.js clients via SSE (Server-Sent Events)
    - NO stream processing, NO computation, NO aggregation
    - Session affinity for persistent SSE connections

3. **Why SSE over WebSockets?**
    - **Simplicity**: Browser-native, no special client library required
    - **One-way push**: Perfect for server-to-client real-time updates
    - **HTTP/2 friendly**: Works through firewalls and proxies
    - **Automatic reconnection**: Built-in browser retry logic
    - **Lower overhead**: No handshake protocol, just chunked HTTP

### Derived Topics

Flink jobs produce derived topics consumed by services and the Realtime Gateway:

| Topic Name          | Produced By                                 | Key                       | Purpose                                                                               | Consumed By                       | UI Surface                         |
|---------------------|---------------------------------------------|---------------------------|---------------------------------------------------------------------------------------|-----------------------------------|------------------------------------|
| `engagement.scores` | Flink Engagement Analytics Job              | `studentId`               | Real-time engagement metrics per student (score, alert thresholds, patterns)          | Realtime Gateway, Bandit Engine   | Student UI (engagement indicator)  |
| `decision.context`  | Flink Engagement Analytics Job              | `sessionId`               | Enriched context for AI decision-making (student history, current state, performance) | Bandit Engine, Tip Service        | N/A (internal)                     |
| `adapt.actions`     | Bandit Engine (consumes `decision.context`) | `studentId`               | AI-driven adaptation actions (difficulty adjust, hint trigger, content change)        | Realtime Gateway, Content Adapter | Student UI (hints, new questions)  |
| `instructor.tips`   | Flink Instructor Metrics Job                | `cohortId` or `studentId` | Coaching suggestions for instructors (struggling students, skill gaps)                | Realtime Gateway                  | Instructor Dashboard (alerts)      |
| `cohort.heatmap`    | Flink Instructor Metrics Job                | `cohortId`                | Aggregated cohort performance heatmap data (skill Ã— difficulty matrix)                | Realtime Gateway                  | Instructor Dashboard (heatmap viz) |

**Note**: Raw topics (`quiz.answers`, `session.events`) are produced by Event Ingest Service and consumed by Flink jobs.

### Realtime Gateway Service

**What it does:**

- Consumes derived Kafka topics (`engagement.scores`, `adapt.actions`, `instructor.tips`, `cohort.heatmap`)
- Maintains persistent SSE connections to Next.js clients
- Routes messages to appropriate SSE streams based on routing keys
- Handles connection lifecycle (connect, disconnect, heartbeat)

**What it does NOT do:**

- âŒ Stream processing (windowing, aggregation, joins)
- âŒ Business logic or computation
- âŒ Event enrichment or transformation
- âŒ Stateful operations beyond routing

**Routing Model:**

| Stream Type       | Routing Key | Subscribed By         | Topics Consumed                      |
|-------------------|-------------|-----------------------|--------------------------------------|
| Student Stream    | `studentId` | Student UI            | `engagement.scores`, `adapt.actions` |
| Instructor Stream | `cohortId`  | Instructor Dashboard  | `instructor.tips`, `cohort.heatmap`  |
| Session Stream    | `sessionId` | Both (session-scoped) | All derived topics                   |

**SSE Endpoint Example:**

```javascript
// Frontend (Next.js)
const eventSource = new EventSource(`${GATEWAY_URL}/sse/student/${studentId}`);

eventSource.addEventListener('engagement', (e) => {
    const score = JSON.parse(e.data);
    updateEngagementIndicator(score);
});

eventSource.addEventListener('adapt', (e) => {
    const action = JSON.parse(e.data);
    if (action.type === 'SHOW_HINT') showHint(action.hint);
});
```

---

## Repository Structure

```
edupulse/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ event-ingest-service/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pom.xml
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ bandit-engine/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pom.xml
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ tip-service/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pom.xml
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ content-adapter/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pom.xml
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ realtime-gateway/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pom.xml
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ shared/
â”‚       â””â”€â”€ avro-schemas/
â”‚           â”œâ”€â”€ event-envelope.avsc
â”‚           â”œâ”€â”€ quiz-answer.avsc
â”‚           â”œâ”€â”€ engagement-score.avsc
â”‚           â”œâ”€â”€ adapt-action.avsc
â”‚           â””â”€â”€ instructor-tip.avsc
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ quizzer-frontend (nx monorepo)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â””â”€â”€ terraform/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ register-schemas.sh
â”‚   â”œâ”€â”€ seed-data.sql
â”‚   â””â”€â”€ start-local.sh
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SYSTEM_DESIGN.md
â”‚   â”œâ”€â”€ API.md
â”‚   â””â”€â”€ DEMO.md
â””â”€â”€ README.md (this file)
```

---

## Quick Start

### Prerequisites

- Java 21+
- Node.js 18+
- Docker Desktop
- Confluent Cloud account (or local Kafka with Docker)
- Google Cloud account (for Vertex AI, Gemini)

### One-Command Local Setup

```bash
# Clone repository
git clone https://github.com/EduPulseAI/edupulse.git
cd edupulse

# Start infrastructure (Kafka, PostgreSQL, Redis)
docker compose -f infra/docker/docker-compose up -d

# Set environment variables
cp .env.example .env
# Edit .env with your Confluent Cloud and GCP credentials

# Register Avro schemas
./scripts/register-schemas.sh

# Seed database
psql -h localhost -U edupulse -d edupulse -f scripts/seed-data.sql

## Start all backend services (in separate terminals)
#cd backend/event-ingest-service && ./gradlew bootRun
#cd backend/engagement-service && ./gradlew bootRun
#cd backend/bandit-engine && ./gradlew bootRun
#cd backend/realtime-gateway && ./gradlew bootRun

# Start frontend
#cd frontend && npm install && npm run dev

# Open browser
#open http://localhost:3000
```

---

## Cloud & Infrastructure

### Required GCP Resources

#### Setup

```bash
bash ./scripts/gcloud/setup.sh
```

**Revoke existing auth**

```bash
gcloud auth application-default revoke
```

#### 1. Vertex AI

**Purpose:** Multi-armed bandit inference

**Setup:**

```bash
# Enable Vertex AI API
gcloud services enable aiplatform.googleapis.com

# Create service account
gcloud iam service-accounts create edupulse-vertex \
  --display-name="EduPulse Vertex AI"

# Grant permissions
gcloud projects add-iam-policy-binding PROJECT_ID \
  --member="serviceAccount:edupulse-vertex@PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/aiplatform.user"

# Create key
gcloud iam service-accounts keys create vertex-key.json \
  --iam-account=edupulse-vertex@PROJECT_ID.iam.gserviceaccount.com

# Deploy model (example with pre-trained model)
gcloud ai models upload \
  --region=us-central1 \
  --display-name=edupulse-bandit-v1 \
  --artifact-uri=gs://your-bucket/model/

# Create endpoint
gcloud ai endpoints create \
  --region=us-central1 \
  --display-name=edupulse-bandit-endpoint

# Deploy model to endpoint
gcloud ai endpoints deploy-model ENDPOINT_ID \
  --region=us-central1 \
  --model=MODEL_ID \
  --display-name=edupulse-bandit-v1 \
  --machine-type=n1-standard-4 \
  --min-replica-count=1 \
  --max-replica-count=3
```

#### 2. Gemini API

**Setup:**

```bash
# Enable Vertex AI Gemini API
gcloud services enable generativelanguage.googleapis.com

# Get API key from Cloud Console or use service account
export GEMINI_API_KEY=$(gcloud auth print-access-token)
```

#### 3. Cloud SQL (PostgreSQL)

```bash
# Create instance
gcloud sql instances create edupulse-db \
  --database-version=POSTGRES_15 \
  --tier=db-f1-micro \
  --region=us-central1

# Create database
gcloud sql databases create edupulse \
  --instance=edupulse-db

# Create user
gcloud sql users create edupulse \
  --instance=edupulse-db \
  --password=SECURE_PASSWORD
```

#### 4. Memorystore (Redis)

```bash
# Create instance
gcloud redis instances create edupulse-redis \
  --size=1 \
  --region=us-central1 \
  --redis-version=redis_7_0
```

---

### Confluent Cloud Resources

#### 1. Kafka Cluster

**Setup via UI:**

1. Go to https://confluent.cloud
2. Create account / log in
3. Create environment: "EduPulse Production"
4. Create cluster: Standard tier, us-east-1, 3 zones
5. Generate API keys:
    - Cluster API key (for Kafka)
    - Schema Registry API key

**Setup via CLI:**

```bash
# Install Confluent CLI
brew install confluentinc/tap/cli

# Login
confluent login

# Create cluster
confluent kafka cluster create edupulse-cluster \
  --cloud aws \
  --region us-east-1 \
  --type standard

# Get bootstrap servers
confluent kafka cluster describe

# Create API key
confluent api-key create --resource <cluster-id>
```

#### 2. Topics

```bash
# Create topics
confluent kafka topic create session.events --partitions 6
confluent kafka topic create quiz.answers --partitions 6
confluent kafka topic create engagement.scores --partitions 6
confluent kafka topic create adapt.actions --partitions 6
confluent kafka topic create instructor.tips --partitions 3

# Create DLQ topics
confluent kafka topic create quiz.answers.dlq --partitions 3
confluent kafka topic create engagement.scores.dlq --partitions 3
```

#### 3. Schema Registry

```bash
# Get Schema Registry endpoint
confluent schema-registry cluster describe

# Create API key
confluent api-key create --resource <sr-cluster-id>

# Register schemas (see scripts/register-schemas.sh)
./scripts/register-schemas.sh
```

---

### Local Development Setup (Docker Compose)

**Start local infrastructure:**

```bash
docker-compose up -d

# Check health
docker-compose ps

# View logs
docker-compose logs -f kafka
```

**Create topics locally:**

```bash
# Install Kafka CLI tools
brew install kafka

# Create topics
kafka-topics --create --topic session.events --partitions 6 --bootstrap-server localhost:9092
kafka-topics --create --topic quiz.answers --partitions 6 --bootstrap-server localhost:9092
kafka-topics --create --topic engagement.scores --partitions 6 --bootstrap-server localhost:9092
kafka-topics --create --topic adapt.actions --partitions 6 --bootstrap-server localhost:9092
kafka-topics --create --topic instructor.tips --partitions 3 --bootstrap-server localhost:9092

# List topics
kafka-topics --list --bootstrap-server localhost:9092
```

---

### Complete Environment Variable Reference

**.env (for local development):**

```bash
# Kafka (Confluent Cloud or local)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_API_KEY=
KAFKA_API_SECRET=

# Schema Registry
SCHEMA_REGISTRY_URL=http://localhost:8081
SCHEMA_REGISTRY_KEY=
SCHEMA_REGISTRY_SECRET=

# PostgreSQL
POSTGRES_URL=jdbc:postgresql://localhost:5432/edupulse
POSTGRES_USER=edupulse
POSTGRES_PASSWORD=edupulse

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# Google Cloud
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
VERTEX_AI_PROJECT_ID=your-project-id
VERTEX_AI_LOCATION=us-central1
VERTEX_AI_ENDPOINT=projects/.../locations/.../endpoints/...
GEMINI_API_KEY=your-gemini-key

# Service Ports
EVENT_INGEST_PORT=8081
ENGAGEMENT_SERVICE_PORT=8082
BANDIT_ENGINE_PORT=8083
TIP_SERVICE_PORT=8084
CONTENT_ADAPTER_PORT=8085
REALTIME_GATEWAY_PORT=8086

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8081
NEXT_PUBLIC_GATEWAY_URL=http://localhost:8086
```

---

### One-Command Startup

**scripts/start-local.sh:**

```bash
#!/bin/bash
set -e

echo "ğŸš€ Starting EduPulse local environment..."

# Start infrastructure
echo "ğŸ“¦ Starting Docker containers..."
docker-compose up -d

# Wait for services
echo "â³ Waiting for services to be ready..."
sleep 10

# Create topics
echo "ğŸ“ Creating Kafka topics..."
kafka-topics --create --if-not-exists --topic session.events --partitions 6 --bootstrap-server localhost:9092
kafka-topics --create --if-not-exists --topic quiz.answers --partitions 6 --bootstrap-server localhost:9092
kafka-topics --create --if-not-exists --topic engagement.scores --partitions 6 --bootstrap-server localhost:9092
kafka-topics --create --if-not-exists --topic adapt.actions --partitions 6 --bootstrap-server localhost:9092
kafka-topics --create --if-not-exists --topic instructor.tips --partitions 3 --bootstrap-server localhost:9092

# Register schemas
echo "ğŸ“‹ Registering Avro schemas..."
./scripts/register-schemas.sh

# Seed database
echo "ğŸŒ± Seeding database..."
psql -h localhost -U edupulse -d edupulse -f scripts/seed-data.sql

echo "âœ… Infrastructure ready!"
echo ""
echo "Start backend services (in separate terminals):"
echo "  cd backend/event-ingest-service && ./gradlew bootRun"
echo "  cd backend/engagement-service && ./gradlew bootRun"
echo "  cd backend/bandit-engine && ./gradlew bootRun"
echo "  cd backend/realtime-gateway && ./gradlew bootRun"
echo ""
echo "Start frontend:"
echo "  cd frontend && npm run dev"
echo ""
echo "Open http://localhost:3000"
```

**Run:**

```bash
chmod +x scripts/start-local.sh
./scripts/start-local.sh
```

---

## Schema Registry & Avro

### Schema Folder Strategy

**Location:** `backend/common/src/main/avro`

**Structure:**

```
backend/shared/avro-schemas/
â”œâ”€â”€ common/
â”‚   â””â”€â”€ event-envelope.avsc
â”œâ”€â”€ session/
â”‚   â”œâ”€â”€ session-event.avsc
â”‚   â””â”€â”€ session-event-key.avsc
â”œâ”€â”€ quiz/
â”‚   â”œâ”€â”€ quiz-answer.avsc
â”‚   â””â”€â”€ quiz-answer-key.avsc
â”œâ”€â”€ engagement/
â”‚   â””â”€â”€ engagement-score.avsc
â”œâ”€â”€ adapt/
â”‚   â””â”€â”€ adapt-action.avsc
â””â”€â”€ instructor/
    â””â”€â”€ instructor-tip.avsc
```

### Register Schemas Script

**scripts/register-schemas.sh:**

```bash
#!/bin/bash
set -e

SCHEMA_REGISTRY_URL=${SCHEMA_REGISTRY_URL:-http://localhost:8081}
SCHEMA_DIR="backend/shared/avro-schemas"

echo "Registering schemas to $SCHEMA_REGISTRY_URL..."

# Function to register schema
register_schema() {
    local subject=$1
    local schema_file=$2
    
    echo "Registering $subject..."
    
    curl -X POST \
        -H "Content-Type: application/vnd.schemaregistry.v1+json" \
        --data "{\"schema\": $(cat $schema_file | jq -R -s -c .)}" \
        "$SCHEMA_REGISTRY_URL/subjects/$subject/versions"
    
    echo ""
}

# Register event envelope (referenced by other schemas)
register_schema "event-envelope" "$SCHEMA_DIR/common/event-envelope.avsc"

# Register quiz schemas
register_schema "quiz.answers-key" "$SCHEMA_DIR/quiz/quiz-answer-key.avsc"
register_schema "quiz.answers-value" "$SCHEMA_DIR/quiz/quiz-answer.avsc"

# Register engagement schemas
register_schema "engagement.scores-value" "$SCHEMA_DIR/engagement/engagement-score.avsc"

# Register adapt schemas
register_schema "adapt.actions-value" "$SCHEMA_DIR/adapt/adapt-action.avsc"

# Register instructor schemas
register_schema "instructor.tips-value" "$SCHEMA_DIR/instructor/instructor-tip.avsc"

echo "âœ… All schemas registered!"

# Set compatibility mode
echo "Setting compatibility mode to BACKWARD..."
curl -X PUT \
    -H "Content-Type: application/vnd.schemaregistry.v1+json" \
    --data '{"compatibility": "BACKWARD"}' \
    "$SCHEMA_REGISTRY_URL/config"

echo ""
echo "âœ… Schema Registry configured!"
```

### Gradle Avro Plugin

**backend/engagement-service/build.gradle:**

```gradle
plugins {
    id "com.github.davidmc24.gradle.plugin.avro" version "1.9.1"
}

dependencies {
    implementation 'org.apache.avro:avro:1.11.3'
}

avro {
    fieldVisibility = "PRIVATE"
    outputCharacterEncoding = "UTF-8"
    stringType = "String"
}

// Generate Java classes from .avsc files
generateAvroJava {
    source = file("../shared/avro-schemas")
}
```

**Generate classes:**

```bash
cd backend/engagement-service
./gradlew generateAvroJava
```

---

## Demo Instructions

### Pre-Demo Setup (5 minutes)

1. **Start all services:**

```bash
# Terminal 1: Infrastructure
docker-compose up -d

# Terminal 2: Event Ingest
cd backend/event-ingest-service && ./gradlew bootRun

# Terminal 3: Engagement Service
cd backend/engagement-service && ./gradlew bootRun

# Terminal 4: Bandit Engine
cd backend/bandit-engine && ./gradlew bootRun

# Terminal 5: Realtime Gateway
cd backend/realtime-gateway && ./gradlew bootRun

# Terminal 6: Frontend
cd frontend && npm run dev
```

2. **Open browser windows:**

- Student UI: http://localhost:3000/student/alice
- Instructor Dashboard: http://localhost:3000/instructor/dashboard
- Confluent Cloud UI: https://confluent.cloud (show live topics)

3. **Pre-warm services:**

```bash
# Call Vertex AI once to avoid cold start
curl -X POST http://localhost:8083/api/health/vertex-ai
```

---

### Demo Script (3 minutes)

**[0:00-0:30] Setup & Introduction**

> "EduPulse detects student disengagement in real-time and adapts learning experiences using AI on streaming data."

- Show both screens: Student UI (left), Instructor Dashboard (right)
- Point out Alice's green engagement tile (score: 0.72)

**[0:30-1:15] Student Struggles**

> "Watch what happens when Alice struggles with a question..."

1. Alice answers incorrectly (attempt 1)
    - Show: Engagement tile turns yellow (0.51)
2. Alice answers incorrectly (attempt 2)
    - Show: Engagement tile turns orange (0.45)
3. Alice answers incorrectly (attempt 3)
    - Show: Engagement tile turns red (0.38) with alert icon
    - Instructor dashboard: Tip appears "Alice may need help with linear equations..."

**[1:15-2:00] AI Intervention**

> "EduPulse's AI responds in milliseconds. Let me show you what's happening under the hood..."

- Switch to Confluent Cloud UI
- Show messages flowing through quiz.answers topic
- Show engagement.scores topic with alertThresholdCrossed = true
- Point out Avro schema enforcement

> "Our bandit model at Vertex AI selects the optimal difficulty..."

- Show adapt.actions topic with DIFFICULTY_ADJUST
- Show modelMetadata: inference latency ~187ms

**[2:00-2:30] Student Recovery**

> "Watch Alice's screen..."

- Hint appears: "Try isolating the variable by working backwards"
- New easier question appears (difficulty 2 vs 4)
- Alice answers correctly
- Engagement tile recovers to green (0.68)

**[2:30-3:00] Schema Governance**

> "Everything you saw is governed by Avro schemas in Schema Registry..."

- Show Schema Registry UI
- Point out BACKWARD compatibility
- Mention schema evolution example (optional field addition)

> "This architecture is production-ready: event sourcing, schema governance, and sub-500ms AI-driven personalization."

---

### Demo Checklist

**Before presenting:**

- [ ] All services healthy (check actuator/health endpoints)
- [ ] SSE connections established (test with EventSource)
- [ ] Alice's initial state reset (engagement: 0.72, difficulty: 4)
- [ ] Instructor dashboard showing 3-5 students
- [ ] Confluent Cloud UI open (topics tab)
- [ ] Demo questions loaded (q1-q5)
- [ ] Backup video accessible
- [ ] Laptop charged, HDMI adapter ready

**During demo:**

- [ ] Speak clearly and slowly
- [ ] Point mouse at relevant UI elements
- [ ] Show timestamps/latency numbers
- [ ] Highlight "real-time" updates
- [ ] Mention Kafka, Avro, Schema Registry by name

**After demo:**

- [ ] Thank judges
- [ ] Offer to answer questions
- [ ] Provide GitHub link or QR code

---

## Troubleshooting

### Kafka Connection Issues

**Problem:** `Connection to node -1 could not be established`

**Solution:**

```bash
# Check Kafka is running
docker-compose ps kafka

# Check bootstrap servers
echo $KAFKA_BOOTSTRAP_SERVERS

# Test connection
kafka-broker-api-versions --bootstrap-server localhost:9092
```

---

### Schema Registry Errors

**Problem:** `Schema not found: event-envelope`

**Solution:**

```bash
# Re-register schemas
./scripts/register-schemas.sh

# Verify registration
curl http://localhost:8081/subjects
```

---

### Avro Deserialization Errors

**Problem:** `Error deserializing Avro message for id 123`

**Solution:**

```bash
# Check schema compatibility
curl -X POST \
  http://localhost:8081/compatibility/subjects/quiz.answers-value/versions/latest \
  -d @backend/shared/avro-schemas/quiz/quiz-answer.avsc

# If incompatible, check DLQ topic
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic quiz.answers.dlq \
  --from-beginning
```

---

### SSE Connection Issues

**Problem:** SSE connection closes immediately or fails to establish

**Solution:**

```bash
# Check SSE endpoint is accessible
curl -N -H "Accept: text/event-stream" \
  https://realtime-gateway-xyz.run.app/sse/student/test-student-123

# Verify CORS configuration allows SSE
# In RealtimeGatewayController.java, ensure:
# @CrossOrigin(origins = "*", allowedHeaders = "*")

# Check Kafka consumer is running and consuming derived topics
# View logs:
gcloud run services logs read realtime-gateway --region us-central1 --limit 100

# Test with JavaScript EventSource
node -e "const EventSource = require('eventsource'); const es = new EventSource('http://localhost:8086/sse/student/alice'); es.onmessage = console.log;"
```

---

### Vertex AI Timeout

**Problem:** `Vertex AI call timed out after 500ms`

**Solution:**

```bash
# Increase timeout
# In application.yml:
vertex:
  ai:
    timeout-ms: 2000

# Verify fallback is working
curl http://localhost:8083/actuator/metrics/bandit.fallback.count
```

---

### PostgreSQL Connection Refused

**Problem:** `Connection to localhost:5432 refused`

**Solution:**

```bash
# Check PostgreSQL is running
docker-compose ps postgres

# Test connection
psql -h localhost -U edupulse -d edupulse -c "SELECT 1"

# Check environment variable
echo $POSTGRES_URL
```

---

**For additional help:**

- Check service logs: `docker-compose logs -f <service-name>`
- View Spring Boot actuator: `curl http://localhost:808X/actuator/health`
- Monitor Kafka in Confluent Cloud UI
- Review SYSTEM_DESIGN.md for architecture details

---

**End of README**